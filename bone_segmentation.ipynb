{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bone Segmentation #\n",
    "\n",
    "### Author: Angelo Antonio Manzatto ###\n",
    "\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Libraries\n",
    "##################################################################################  \n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "import random\n",
    "import glob\n",
    "import zipfile\n",
    "import shutil \n",
    "import pydicom\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input,Activation\n",
    "from keras.layers import Conv2D,  MaxPooling2D, BatchNormalization, Conv2DTranspose, concatenate\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Download Dataset\n",
    "##################################################################################  \n",
    "def process_ircad_database(database_url, inputs_folder, bone_masks_folder, overwrite=False):\n",
    "    \n",
    "    # Database name will be assumed as the name on the last \"/\" before the \".zip\"\n",
    "    database_name = database_url.split('/')[-1].split(\".zip\")[0]\n",
    "    \n",
    "    print(50*'-')\n",
    "    print(\"Processing: {0}\".format(database_name))\n",
    "    print(50*'-')\n",
    "    \n",
    "    # Download the dataset if doesn't exist and extract to appropriate folder\n",
    "    database_folder = os.path.join(dataset_folder,database_name)\n",
    "    \n",
    "    if not os.path.exists(database_folder):\n",
    "        os.makedirs(database_folder)\n",
    "    \n",
    "    # Request files\n",
    "    r = requests.get(database_url)\n",
    "    \n",
    "    print(\"Request status code: {0}\".format(r.status_code))\n",
    "    \n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    \n",
    "    r.close()\n",
    "\n",
    "    print(\"Database downloaded\")\n",
    "    print(50*'-')\n",
    "    \n",
    "    # Extract data to folder\n",
    "    z.extractall(dataset_folder)\n",
    "    z.close()\n",
    "    \n",
    "    print(\"Files extracted\")\n",
    "    print(50*'-')\n",
    "    \n",
    "    # Unzip Laled dicom\n",
    "    label_dicom_zip_file = os.path.join(database_folder,'PATIENT_DICOM.zip')\n",
    "    label_dicom_zip = zipfile.ZipFile(label_dicom_zip_file)\n",
    "    label_dicom_zip.extractall(database_folder)\n",
    "    label_dicom_zip.close()\n",
    "    \n",
    "    # Unzip masks dicom\n",
    "    mask_dicom_zip_file = os.path.join(database_folder,'MASKS_DICOM.zip')\n",
    "    mask_dicom_zip = zipfile.ZipFile(mask_dicom_zip_file)\n",
    "    mask_dicom_zip.extractall(database_folder)\n",
    "    mask_dicom_zip.close()\n",
    "    \n",
    "    print(\"Label and Masks extracted\")\n",
    "    print(50*'-')\n",
    "    \n",
    "    # Folders form input and bone masks dicom\n",
    "    label_dicom_folder = os.path.join(database_folder,'PATIENT_DICOM') \n",
    "    bone_mask_dicom_folder = os.path.join(database_folder,'MASKS_DICOM','bone') \n",
    "    \n",
    "    # Select all input and mask dicom files\n",
    "    label_dicom_paths = glob.glob(os.path.join(label_dicom_folder,'*')) \n",
    "    bone_mask_dicom_paths = glob.glob(os.path.join(bone_mask_dicom_folder,'*')) \n",
    "    \n",
    "    n_label = len(label_dicom_paths)\n",
    "    n_bone_masks = len(bone_mask_dicom_paths) \n",
    "    print(\"Label files: {0}\".format(n_label))\n",
    "    print(\"Bone mask files: {0}\".format(n_bone_masks))\n",
    "    print(50*'-')\n",
    "    # Check if we have files and both input and mask folder have the same number of files\n",
    "    assert(len(label_dicom_paths) == len(bone_mask_dicom_paths) and len(label_dicom_paths) > 0 and len(bone_mask_dicom_paths) > 0)\n",
    "\n",
    "    # Move files to appropriate folder\n",
    "\n",
    "    current_index = 1\n",
    "    \n",
    "    # Update the current_index with the last file index on the folder\n",
    "    if(overwrite == False):\n",
    "        \n",
    "        input_dicom_paths = glob.glob(os.path.join(inputs_folder,'*.dcm'))\n",
    "        \n",
    "        if(len(input_dicom_paths) == 0):\n",
    "            current_index = 1\n",
    "        else:\n",
    "            # Grab the file names and extract just the number so input00012.dicom -> 12\n",
    "            indices = [int(x.split(\"\\\\\")[-1][5:10])  for x in input_dicom_paths]\n",
    "            indices.sort()\n",
    "            last_index = indices[-1]\n",
    "            \n",
    "            current_index = last_index + 1\n",
    "    \n",
    "    print(\"Moving files starting with index: {0}\".format(current_index))\n",
    "    print(50*'-')     \n",
    "    \n",
    "    for label_dicom_path, bone_mask_dicom_path in zip(label_dicom_paths, bone_mask_dicom_paths):\n",
    "    \n",
    "        assert(label_dicom_path.split(\"\\\\\")[-1] == bone_mask_dicom_path.split(\"\\\\\")[-1])\n",
    "        \n",
    "        new_input_dicom_path = os.path.join(inputs_folder,'input' + str(current_index).zfill(5) + \".dcm\")\n",
    "        new_bone_mask_dicom_path = os.path.join(bone_masks_folder,'mask' + str(current_index).zfill(5) + \".dcm\")\n",
    "        \n",
    "        shutil.copy(label_dicom_path, new_input_dicom_path)\n",
    "        shutil.copy(bone_mask_dicom_path, new_bone_mask_dicom_path)\n",
    "        \n",
    "        current_index +=1\n",
    "    \n",
    "    print(\"Moving process complete\")\n",
    "    print(50*'-')    \n",
    "    \n",
    "    # Delete temporaty database folder after we exctracted files we wantes\n",
    "    shutil.rmtree(database_folder)\n",
    "    \n",
    "    print(\"Database folder excluded\")\n",
    "    print(50*'-')  \n",
    "            \n",
    "dataset_folder = 'dataset'\n",
    "\n",
    "inputs_folder = os.path.join(dataset_folder,'inputs')\n",
    "bone_masks_folder = os.path.join(dataset_folder,'bone_masks')\n",
    "\n",
    "database_urls = [\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.1.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.2.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.3.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.4.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.5.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.6.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.7.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.8.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.9.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.10.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.11.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.12.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.13.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.14.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.15.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.16.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.17.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.18.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.19.zip',\n",
    "                 'https://www.ircad.fr/softwares/3Dircadb/3Dircadb1/3Dircadb1.20.zip',\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset folder \n",
    "if not os.path.exists(dataset_folder):\n",
    "    os.makedirs(dataset_folder)\n",
    "    \n",
    "# Create Input DICOM folder \n",
    "if not os.path.exists(inputs_folder):\n",
    "    os.makedirs(inputs_folder)\n",
    "    \n",
    "# Create Bone Masks folder\n",
    "if not os.path.exists(bone_masks_folder):\n",
    "    os.makedirs(bone_masks_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this line ONLY if you want to download and process the dataset\n",
    "# The request library hangs sometimes after processing the last request. If that happens you have to start the process\n",
    "# again from the dataset that you have stoped\n",
    "for database_url in database_urls:\n",
    "    process_ircad_database(database_url,inputs_folder,bone_masks_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# Load data\n",
    "############################################################################################\n",
    "    \n",
    "# Load a DICOM file and convert it to [0-255] gray scale    \n",
    "# For IRC  Dataset minimum value = -2048 and maximum value = 3247\n",
    "def load_dicom(dicom_path):\n",
    "    \n",
    "    # Load dicom file\n",
    "    dicom = pydicom.read_file(dicom_path)\n",
    "    \n",
    "    # Select only pixel image data\n",
    "    pixel_data = dicom.pixel_array \n",
    "\n",
    "    intercept = dicom.RescaleIntercept\n",
    "    slope = dicom.RescaleSlope\n",
    "    \n",
    "    # Normalize data using slope and intercept\n",
    "    pixel_data = pixel_data * slope +intercept \n",
    "\n",
    "    image = np.zeros(pixel_data.shape)\n",
    "    \n",
    "    # Normalize image from 16 bits int to 8 bits unsigned int (JPG)\n",
    "    image = (pixel_data + 65535)\n",
    "    image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    image[image > 255] = 255\n",
    "    image[image < 1] = 0\n",
    "          \n",
    "    return image.astype('uint8')\n",
    "\n",
    "    \n",
    "# DICOM image files\n",
    "input_files = glob.glob(os.path.join(inputs_folder,'*.dcm'))  \n",
    "bone_mask_files = glob.glob(os.path.join(bone_masks_folder,'*.dcm'))   \n",
    "\n",
    "# Sort names to avoid connecting wrong numbered files\n",
    "input_files.sort()\n",
    "bone_mask_files.sort()\n",
    "\n",
    "assert(len(input_files) == len(bone_mask_files))\n",
    "\n",
    "# Our dataset is created using the tuple (input image file, ground truth image file)\n",
    "data = []\n",
    "for input_image, bone_mask_image in zip(input_files, bone_mask_files):\n",
    "    \n",
    "    data.append((input_image,bone_mask_image))\n",
    "\n",
    "# Plot some samples from dataset\n",
    "n_samples = 5\n",
    "\n",
    "for i in range(n_samples):\n",
    "    \n",
    "    # define the size of images\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    f.set_figwidth(10)\n",
    "    \n",
    "    # randomly select a sample\n",
    "    idx = np.random.randint(0, len(data))\n",
    "    input_image_path, bone_mask_image_path = data[idx]\n",
    "    \n",
    "    input_image = load_dicom(input_image_path)\n",
    "    bone_mask_image = load_dicom(bone_mask_image_path) \n",
    "    \n",
    "    ax1.imshow(input_image, cmap = 'gray')\n",
    "    ax1.set_title('Input Image # {0}'.format(idx))\n",
    "    \n",
    "    ax2.imshow(bone_mask_image, cmap = 'gray')\n",
    "    ax2.set_title('Bone Mask Image # {0}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# Data Augmentation \n",
    "############################################################################################\n",
    "    \n",
    "#############################\n",
    "# Resize Image\n",
    "#############################\n",
    "class Resize(object):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        \n",
    "        assert isinstance(input_size,(int, tuple))\n",
    "        assert isinstance(output_size,(int, tuple))\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size    \n",
    "        \n",
    "    def __call__(self, input_image, mask_image):     \n",
    "           \n",
    "        h_in, w_in = input_image.shape[:2]\n",
    "        h_out, w_out = mask_image.shape[:2]\n",
    "        \n",
    "        if isinstance(self.input_size, int):\n",
    "            if h_in > w_in:\n",
    "                new_h_in, new_w_in = self.input_size * h_in / w_in, self.input_size\n",
    "            else:\n",
    "                new_h_in, new_w_in = self.input_size, self.input_size * w_in / h_in\n",
    "        else:\n",
    "            new_h_in, new_w_in = self.input_size\n",
    "        \n",
    "        if isinstance(self.output_size, int):\n",
    "            if h_out > w_out:\n",
    "                new_h_out, new_w_out = self.output_size * h_out / w_out, self.output_size\n",
    "            else:\n",
    "                new_h_out, new_w_out = self.output_size, self.output_size * w_out / h_out\n",
    "        else:\n",
    "            new_h_out, new_w_out = self.output_size\n",
    "\n",
    "        new_h_in, new_w_in = int(new_h_in), int(new_w_in)\n",
    "        new_h_out, new_w_out = int(new_h_out), int(new_w_out)\n",
    "\n",
    "        input_image = cv2.resize(input_image, (new_w_in, new_h_in))\n",
    "        mask_image = cv2.resize(mask_image, (new_w_out, new_h_out)) \n",
    "        \n",
    "        return input_image,  mask_image\n",
    "\n",
    "#############################\n",
    "# Translate Image\n",
    "#############################    \n",
    "class RandomTranslation(object):\n",
    "\n",
    "    def __init__(self, ratio = 0.4, background_color = (0) , prob=0.5):\n",
    "        \n",
    "        self.background_color  = background_color\n",
    "        self.ratio = ratio\n",
    "        self.prob  = prob\n",
    "        \n",
    "    def __call__(self, input_image, mask_image):\n",
    "                \n",
    "        if random.uniform(0, 1) <= self.prob:\n",
    "            \n",
    "            img_h, img_w = input_image.shape\n",
    "            \n",
    "            x = int(np.random.uniform(-self.ratio,self.ratio) * img_w)\n",
    "            y = int(np.random.uniform(-self.ratio,self.ratio) * img_h)\n",
    "\n",
    "            M = np.float32([[1, 0, x],\n",
    "                            [0, 1, y]])\n",
    "                \n",
    "            input_image_translated = cv2.warpAffine(input_image,M,(img_w,img_h), borderValue=self.background_color)\n",
    "            imask_image_translated = cv2.warpAffine(mask_image,M,(img_w,img_h), borderValue=self.background_color)\n",
    "            \n",
    "            return input_image_translated , imask_image_translated\n",
    "           \n",
    "        return input_image, mask_image\n",
    "\n",
    "#############################\n",
    "# Scale Image\n",
    "#############################  \n",
    "class RandomScale(object):\n",
    "\n",
    "    def __init__(self, lower = 0.4, upper = 1.4, background_color = (0) , prob=0.5):\n",
    "        \n",
    "        self.background_color = background_color\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        self.prob  = prob  \n",
    "        \n",
    "    def __call__(self, input_image, mask_image):\n",
    "                \n",
    "        if random.uniform(0, 1) <= self.prob:\n",
    "            \n",
    "            input_img_h, input_img_w = input_image.shape\n",
    "            mask_img_h, mask_img_w = mask_image.shape\n",
    "            \n",
    "             # Create canvas with random ration between lower and upper\n",
    "            ratio = random.uniform(self.lower,self.upper)\n",
    "            \n",
    "            scale_x = ratio\n",
    "            scale_y = ratio\n",
    "            \n",
    "            # Scale the image\n",
    "            scaled_input_image = cv2.resize(input_image.astype('float32'),(0,0),fx=scale_x,fy=scale_y)\n",
    "            scaled_mask_image = cv2.resize(mask_image.astype('float32'),(0,0),fx=scale_x,fy=scale_y)\n",
    "            \n",
    "            top = 0\n",
    "            left = 0\n",
    "            \n",
    "            if ratio < 1:\n",
    "                    \n",
    "                # Input image\n",
    "                background = np.zeros((input_img_h, input_img_w), dtype = np.uint8)\n",
    "                \n",
    "                background[:,:] = self.background_color \n",
    "            \n",
    "                y_lim = int(min(scale_x,1)*input_img_h)\n",
    "                x_lim = int(min(scale_y,1)*input_img_w)\n",
    "                \n",
    "                top  = (input_img_h - y_lim) // 2\n",
    "                left = (input_img_w - x_lim) // 2\n",
    "\n",
    "                background[top:y_lim+top,left:x_lim+left] = scaled_input_image[:y_lim,:x_lim]\n",
    "                \n",
    "                scaled_input_image = background\n",
    "                \n",
    "                # Mask image                \n",
    "                background = np.zeros((mask_img_h, mask_img_w), dtype = np.uint8)\n",
    "                \n",
    "                background[:,:] = self.background_color \n",
    "                \n",
    "                y_lim = int(min(scale_x,1)*mask_img_h)\n",
    "                x_lim = int(min(scale_y,1)*mask_img_w)\n",
    "                \n",
    "                top  = (mask_img_h - y_lim) // 2\n",
    "                left = (mask_img_w - x_lim) // 2\n",
    "                \n",
    "                background[top:y_lim+top,left:x_lim+left] = scaled_mask_image[:y_lim,:x_lim]\n",
    "                \n",
    "                scaled_mask_image = background\n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                top  = (scaled_input_image.shape[0] -  input_img_h) // 2\n",
    "                left = (scaled_input_image.shape[1] -  input_img_w) // 2\n",
    "                \n",
    "                scaled_input_image = scaled_input_image[top:input_img_h+top,left:input_img_w+left]\n",
    "                \n",
    "                top  = (scaled_mask_image.shape[0] -  mask_img_h) // 2\n",
    "                left = (scaled_mask_image.shape[1] -  mask_img_w) // 2\n",
    "                \n",
    "                scaled_mask_image = scaled_mask_image[top:mask_img_h+top,left:mask_img_w+left]\n",
    "                         \n",
    "            return scaled_input_image, scaled_mask_image\n",
    "\n",
    "        return input_image, mask_image\n",
    "    \n",
    "#############################\n",
    "# Flip image\n",
    "#############################    \n",
    "class RandomFlip(object):\n",
    " \n",
    "    def __init__(self, prob=0.5):\n",
    "\n",
    "        self.prob = prob\n",
    "        \n",
    "    def __call__(self, input_image, mask_image):\n",
    "        \n",
    "        if random.uniform(0, 1) <= self.prob:\n",
    "        \n",
    "            # Get image shape\n",
    "            h, w = input_image.shape[:2]\n",
    "            \n",
    "            # Flip image\n",
    "            input_image = input_image[:, ::-1]\n",
    "            \n",
    "            # Get image shape\n",
    "            h, w = mask_image.shape[:2]\n",
    "            \n",
    "            # Flip image\n",
    "            mask_image = mask_image[:, ::-1]\n",
    "            \n",
    "            # Random flip horizontally\n",
    "            if random.uniform(0, 1) <= 0.5 :\n",
    "                \n",
    "                input_image = np.flip(input_image)\n",
    "                mask_image = np.flip(mask_image)\n",
    "            \n",
    "            return input_image, mask_image\n",
    "        \n",
    "        return input_image, mask_image\n",
    "\n",
    "#############################\n",
    "# Change image brightness\n",
    "############################# \n",
    "class RandomBrightness():\n",
    "    \n",
    "    def __init__(self, lower = -25, upper = 25, prob = 0.5):\n",
    "\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        self.prob = prob\n",
    "    \n",
    "    def __call__(self, input_image,  mask_image):\n",
    "        \n",
    "        if random.uniform(0, 1) <= self.prob:\n",
    "            \n",
    "            amount = int(random.uniform(self.lower, self.upper))\n",
    "            \n",
    "            input_image = np.clip(input_image + amount, 0, 255).astype(\"uint8\")\n",
    "        \n",
    "            return input_image, mask_image\n",
    "        \n",
    "        return input_image, mask_image\n",
    "\n",
    "#############################\n",
    "# Change image contrast\n",
    "############################# \n",
    "class RandomContrast():\n",
    "    \n",
    "    def __init__(self, lower = 0.5, upper = 1.5, prob = 0.5):\n",
    "\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        self.prob = prob\n",
    "    \n",
    "    def __call__(self, input_image,  mask_image):\n",
    "        \n",
    "        if random.uniform(0, 1) <= self.prob:\n",
    "            \n",
    "            amount = random.uniform(self.lower, self.upper)\n",
    "            \n",
    "            input_image = np.clip(input_image * amount, 0, 255).astype(\"uint8\")\n",
    "        \n",
    "            return input_image, mask_image\n",
    "        \n",
    "        return input_image, mask_image\n",
    "    \n",
    "#############################    \n",
    "# Gaussian Noise\n",
    "#############################    \n",
    "class GaussianNoise(object):\n",
    "    \n",
    "    def __init__(self,mean=0.0, var=0.1, prob=0.5):\n",
    "\n",
    "        self.mean = mean\n",
    "        self.var = var\n",
    "        self.prob = prob\n",
    "    \n",
    "    def __call__(self, input_image, mask_image):\n",
    "        \n",
    "        if random.uniform(0, 1) <= self.prob:\n",
    "        \n",
    "             # Get image shape\n",
    "            h, w = input_image.shape[:2]\n",
    "            \n",
    "            sigma = self.var **0.5\n",
    "            \n",
    "            gauss = np.random.normal(self.mean,sigma,(w,h))\n",
    "            gauss = gauss.reshape(w,h)\n",
    "            \n",
    "            noise_input_image = input_image + gauss\n",
    "            \n",
    "            return noise_input_image, mask_image\n",
    "        \n",
    "        return input_image, mask_image\n",
    "\n",
    "\n",
    "#############################\n",
    "# Normalize\n",
    "#############################\n",
    "class Normalize(object):\n",
    "    \n",
    "    \"\"\"Normalize the color range to [0,1].\"\"\" \n",
    "       \n",
    "    def __call__(self, input_image, mask_image):\n",
    "                    \n",
    "        return input_image / 255 , mask_image / 255 \n",
    "\n",
    "############################################################################################\n",
    "# Test Data Augmentation \n",
    "############################################################################################\n",
    "def plot_transformation(transformation, n_samples = 3, normalize = False):\n",
    "\n",
    "    for i in range(n_samples):\n",
    "    \n",
    "        # define the size of images\n",
    "        f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "        f.set_figwidth(14)\n",
    "\n",
    "        # randomly select a sample\n",
    "        idx = np.random.randint(0, len(data))\n",
    "        input_image_path, bone_mask_image_path = data[idx]\n",
    "    \n",
    "        input_image = load_dicom(input_image_path)\n",
    "        bone_mask_image = load_dicom(bone_mask_image_path)\n",
    "        \n",
    "        if normalize:\n",
    "            norm = Normalize()\n",
    "            input_image, bone_mask_image = norm(input_image, bone_mask_image)\n",
    "\n",
    "        new_input_image, new_bone_mask_image = transformation(input_image, bone_mask_image)\n",
    "        \n",
    "        ax1.imshow(input_image , cmap = 'gray')\n",
    "        ax1.set_title('Original Input')\n",
    "        \n",
    "        ax2.imshow(new_input_image , cmap = 'gray')\n",
    "        ax2.set_title(type(transformation).__name__)\n",
    "\n",
    "        ax3.imshow(bone_mask_image , cmap = 'gray')\n",
    "        ax3.set_title('Original Bone Mask')\n",
    "        \n",
    "        ax4.imshow(new_bone_mask_image , cmap = 'gray')\n",
    "        ax4.set_title(type(transformation).__name__)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Resize Test\n",
    "##########################\n",
    "resize = Resize((512, 512),(512, 512))\n",
    "plot_transformation(resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Random Translation\n",
    "##########################\n",
    "translation = RandomTranslation(ratio = 0.2, prob=1.0)\n",
    "plot_transformation(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Random Translation\n",
    "##########################\n",
    "scale = RandomScale(prob=1.0)\n",
    "plot_transformation(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Random Brightness Test\n",
    "##########################\n",
    "bright = RandomBrightness(prob=1.0)\n",
    "plot_transformation(bright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Random Contrast Test\n",
    "##########################\n",
    "contrast = RandomContrast(prob=1.0)\n",
    "plot_transformation(contrast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Random Flip Test\n",
    "##########################\n",
    "noise = GaussianNoise(mean=0.0, var=0.001, prob=1.0)\n",
    "plot_transformation(noise, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Normalize Test\n",
    "##########################\n",
    "normalize = Normalize()\n",
    "plot_transformation(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# Create Dataset\n",
    "############################################################################################\n",
    "    \n",
    "# Create X, y tuple from image_path, key_pts tuple\n",
    "def createXy(data, transformations = None):\n",
    "    \n",
    "    input_image_path, bone_mask_image_path = data\n",
    "    \n",
    "    input_image = load_dicom(input_image_path) \n",
    "    bone_mask_image = load_dicom(bone_mask_image_path) \n",
    "    \n",
    "    # Apply transformations for the tuple (image, labels, boxes)\n",
    "    if transformations:\n",
    "        for t in transformations:\n",
    "            input_image, bone_mask_image = t(input_image, bone_mask_image)\n",
    "            \n",
    "    input_image = np.expand_dims(input_image, axis = -1)     \n",
    "    bone_mask_image = np.expand_dims(bone_mask_image, axis = -1)            \n",
    "            \n",
    "    return input_image, bone_mask_image\n",
    "\n",
    "# Generator for using with model\n",
    "def generator(data, transformations = None, batch_size = 4, shuffle_data= True):\n",
    "    \n",
    "    n_samples = len(data)\n",
    "    \n",
    "    # Loop forever for the generator\n",
    "    while 1:\n",
    "        \n",
    "        if shuffle_data:\n",
    "            data = shuffle(data)\n",
    "        \n",
    "        for offset in range(0, n_samples, batch_size): \n",
    "            \n",
    "            batch_samples = data[offset:offset + batch_size]\n",
    "            \n",
    "            X = []\n",
    "            y = []\n",
    "            \n",
    "            for sample_data in batch_samples:\n",
    "                \n",
    "                image, target = createXy(sample_data, transformations)\n",
    "\n",
    "                X.append(image)\n",
    "                y.append(target)\n",
    "                \n",
    "            X = np.asarray(X).astype('float32')\n",
    "            y = np.asarray(y).astype('float32')\n",
    "            \n",
    "            yield (shuffle(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# Unet Model\n",
    "############################################################################################\n",
    "def unet_encoder(inputs,filters, block_id):\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size=(3,3), padding='same' , kernel_initializer='he_normal', name='block_' + str(block_id) + '_unet_encoder_conv2d_1')(inputs)\n",
    "    x = BatchNormalization(name='block_' + str(block_id) + '_unet_encoder_conv_batch_1')(x)\n",
    "    x = Activation('relu', name='block_' + str(block_id) + '_unet_encoder_relu_1')(x)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size=(3,3), padding='same' , kernel_initializer='he_normal', name='block_' + str(block_id) + '_unet_encoder_conv2d_2')(x)\n",
    "    x = BatchNormalization(name='block_' + str(block_id) + '_unet_encoder_conv_batch_2')(x)\n",
    "    x = Activation('relu', name='block_' + str(block_id) + '_unet_encoder_relu_2')(x)\n",
    "    \n",
    "    return x\n",
    "                \n",
    "def unet_encoder_pool(inputs,filters, block_id):\n",
    "    \n",
    "    x = unet_encoder(inputs, filters, block_id)\n",
    "    x = MaxPooling2D(pool_size=(2,2), name='block_' + str(block_id) + '_unet_pooling')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def unet_decoder(inputs_a, inputs_b, filters, block_id):\n",
    "    \n",
    "    x = Conv2DTranspose(filters, kernel_size=(2,2), strides=(2,2), padding='same')(inputs_a)\n",
    "    \n",
    "    x = concatenate([x, inputs_b],axis=3)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size=(3,3), padding='same' , kernel_initializer='he_normal', name='block_' + str(block_id) + '_unet_decoder_conv2d_1')(x)\n",
    "    x = BatchNormalization(name='block_' + str(block_id) + '_unet_decoder_conv_batch_1')(x)\n",
    "    x = Activation('relu', name='block_' + str(block_id) + '_unet_decoder_relu_1')(x)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size=(3,3), padding='same' , kernel_initializer='he_normal', name='block_' + str(block_id) + '_unet_decoder_conv2d_2')(x)\n",
    "    x = BatchNormalization(name='block_' + str(block_id) + '_unet_decoder_conv_batch_2')(x)\n",
    "    x = Activation('relu', name='block_' + str(block_id) + '_unet_decoder_relu_2')(x)\n",
    "    \n",
    "    return x\n",
    "              \n",
    "def UNet(input_shape=(512,512,1)):\n",
    "    \n",
    "    Image = Input(shape=input_shape)\n",
    "    \n",
    "    encoder = unet_encoder_pool(Image,   filters=32,  block_id=0)\n",
    "    encoder = unet_encoder_pool(encoder, filters=64,  block_id=1)\n",
    "    encoder = unet_encoder_pool(encoder, filters=128, block_id=2)\n",
    "    encoder = unet_encoder_pool(encoder, filters=256, block_id=3)\n",
    "    encoder = unet_encoder(encoder, filters=512, block_id=4)\n",
    "    \n",
    "    encoder_model = Model(inputs=Image,outputs=encoder)\n",
    "\n",
    "    tensor1 = encoder_model.get_layer('block_3_unet_encoder_relu_2').output\n",
    "    tensor2 = encoder_model.get_layer('block_2_unet_encoder_relu_2').output\n",
    "    tensor3 = encoder_model.get_layer('block_1_unet_encoder_relu_2').output\n",
    "    tensor4 = encoder_model.get_layer('block_0_unet_encoder_relu_2').output\n",
    "    \n",
    "    decoder = unet_decoder(encoder, tensor1, filters=256, block_id = 4)\n",
    "    decoder = unet_decoder(decoder, tensor2, filters=128, block_id = 5)\n",
    "    decoder = unet_decoder(decoder, tensor3, filters=64, block_id = 6)\n",
    "    decoder = unet_decoder(decoder, tensor4, filters=32, block_id = 7)\n",
    "    \n",
    "    decoder = Conv2D(1,kernel_size=(1,1),strides=(1,1), activation='sigmoid')(decoder)\n",
    "    \n",
    "    model = Model(inputs=Image, outputs=decoder)\n",
    "    \n",
    "    return model\n",
    "\n",
    "############################################################################################\n",
    "# Unet Loss\n",
    "############################################################################################\n",
    "class UNetLoss():\n",
    "    \n",
    "    def __init__(self, smooth = 1):\n",
    "        \n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def calculate_loss(self, y_true, y_pred):\n",
    "        \n",
    "        y_true_f = K.flatten(y_true)\n",
    "        y_pred_f = K.flatten(y_pred)\n",
    "        \n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        coefficient = (2. * intersection + self.smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + self.smooth)\n",
    "        loss = 1 - coefficient\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# Training pipeline\n",
    "############################################################################################\n",
    "\n",
    "# Data augmentation \n",
    "train_transformations = [ \n",
    "        RandomBrightness(prob=0.5),\n",
    "        RandomContrast(prob=0.5),\n",
    "        RandomTranslation(ratio=0.2, prob=0.5),\n",
    "        RandomScale(lower=0.8,upper=1.2, prob=0.5),\n",
    "        RandomFlip(prob=0.5),\n",
    "        Resize((512,512),(512,512)),\n",
    "        Normalize()\n",
    "        ]\n",
    "\n",
    "test_transformations = [\n",
    "        RandomBrightness(prob=0.5),\n",
    "        RandomContrast(prob=0.5),\n",
    "        RandomTranslation(ratio=0.2, prob=0.5),\n",
    "        RandomScale(lower=0.8,upper=1.2, prob=0.5),\n",
    "        RandomFlip(prob=0.5),\n",
    "        Resize((512,512),(512,512)),\n",
    "        Normalize()\n",
    "        ]\n",
    "\n",
    "valid_transformations = [\n",
    "        Resize((512,512),(512,512)),\n",
    "        Normalize()\n",
    "        ]\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 1 # Change this value if you have more GPU Power\n",
    "learning_rate = 0.001\n",
    "weight_decay = 5e-4\n",
    "momentum = .9\n",
    "\n",
    "train_data, test_valid_data = train_test_split(data, test_size=0.20, random_state=42)\n",
    "test_data, valid_data = train_test_split(test_valid_data, test_size=0.50, random_state=42)\n",
    "\n",
    "print('Size of train data: {0}'.format(len(train_data)))\n",
    "print('Size of test data: {0}'.format(len(test_data)))\n",
    "print('Size of valid data: {0}'.format(len(valid_data)))\n",
    "\n",
    "train_generator = generator(train_data, train_transformations, batch_size)\n",
    "test_generator = generator(test_data, test_transformations, batch_size)\n",
    "\n",
    "# callbacks\n",
    "model_path = 'saved_models'\n",
    "\n",
    "model = UNet()\n",
    "model.summary()\n",
    "\n",
    "# Create loss function\n",
    "loss = UNetLoss()\n",
    "\n",
    "# Create Optimizer\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# Compile model for training\n",
    "model.compile(optimizer, loss = loss.calculate_loss, metrics=['accuracy'])\n",
    "\n",
    "# File were the best model will be saved during checkpoint     \n",
    "model_file = os.path.join(model_path,'bone_segmentation-{val_loss:.4f}.h5')\n",
    "\n",
    "# Check point for saving the best model\n",
    "check_pointer = ModelCheckpoint(model_file, monitor='val_loss', mode='min',verbose=1, save_best_only=True)\n",
    "\n",
    "# Logger to store loss on a csv file\n",
    "csv_logger = CSVLogger(filename='bone_segmentation.csv',separator=',', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,steps_per_epoch=int(len(train_data) / batch_size),\n",
    "                              validation_data=test_generator,validation_steps=int(len(test_data) / batch_size),\n",
    "                              epochs=epochs, verbose=1, callbacks=[check_pointer,csv_logger],workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# Predict\n",
    "############################################################################################\n",
    "\n",
    "# If we want to test on a pre trained model use the following line\n",
    "# model.load_weights(os.path.join(model_path,'<path to model file.h5>'), by_name=False)\n",
    "\n",
    "n_samples = 5\n",
    "\n",
    "for i in range(n_samples):\n",
    "    \n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    f.set_figwidth(14)\n",
    "    \n",
    "    # randomly select a sample\n",
    "    idx = np.random.randint(0, len(valid_data))\n",
    "    sample = valid_data[idx]\n",
    "    \n",
    "    # Read input file\n",
    "    input_image_path, bone_mask_image_path = sample\n",
    "    \n",
    "    input_image = load_dicom(input_image_path) \n",
    "    bone_mask_image = load_dicom(bone_mask_image_path) \n",
    "    \n",
    "    input_image_copy = np.copy(input_image)\n",
    "    bone_mask_image_copy = np.copy(bone_mask_image)\n",
    "\n",
    "    # Apply transformations to input and background image\n",
    "    for t in valid_transformations:\n",
    "        input_image_copy,bone_mask_image_copy = t(input_image_copy, bone_mask_image_copy)\n",
    "            \n",
    "    input_image_copy = np.expand_dims(input_image_copy, axis = -1)     \n",
    "    bone_mask_image_copy = np.expand_dims(bone_mask_image_copy, axis = -1)  \n",
    "    \n",
    "    # Predict \n",
    "    bone_mask_pred = model.predict(input_image_copy[np.newaxis,...]) \n",
    "    \n",
    "     # Squeeze\n",
    "    input_image_copy = np.squeeze(input_image_copy)\n",
    "    bone_mask_image_copy = np.squeeze(bone_mask_image_copy)\n",
    "    bone_mask_pred = np.squeeze(bone_mask_pred)\n",
    "\n",
    "    bone_mask_pred[bone_mask_pred > 0.5] = 1\n",
    "    bone_mask_pred[bone_mask_pred <= 0.5] = 0\n",
    "\n",
    "    # Plot \n",
    "    ax1.set_title('Input Image # {0}'.format(idx))\n",
    "    ax1.imshow(input_image_copy , cmap='gray')\n",
    "    \n",
    "    ax2.set_title('True Bone Mask # {0}'.format(idx))\n",
    "    ax2.imshow(bone_mask_image_copy, cmap='gray')\n",
    "    \n",
    "    ax3.set_title('Predicted Bone Mask # {0}'.format(idx))\n",
    "    ax3.imshow(bone_mask_pred, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = np.zeros((len(data),11))\n",
    "statistics = []\n",
    "    \n",
    "for i, sample in enumerate(data):\n",
    "    \n",
    "    # Retrieve tuple\n",
    "    input_image_path, bone_mask_image_path= sample\n",
    "    \n",
    "    print(\"input: {0} , gt: {1}\".format(input_image_path.split(\"\\\\\")[-1], bone_mask_image_path.split(\"\\\\\")[-1]))\n",
    "    \n",
    "    # Read input file\n",
    "    input_image = load_dicom(input_image_path) \n",
    "    bone_mask_image = load_dicom(bone_mask_image_path) \n",
    "    \n",
    "    # Make a copy for safety\n",
    "    input_image_copy = np.copy(input_image)\n",
    "    bone_mask_image_copy = np.copy(bone_mask_image)\n",
    "    \n",
    "    # Apply transformations to input and background image. This time we will not use the ground truth image \n",
    "    # in the transformation step since we want to evaluate against the original data excluding the mask\n",
    "    # Apply transformations to input and background image\n",
    "    for t in valid_transformations:\n",
    "        input_image_copy,bone_mask_image_copy = t(input_image_copy, bone_mask_image_copy)\n",
    "\n",
    "    # Correct single dimensions\n",
    "    input_image_copy = np.expand_dims(input_image_copy, axis = -1)     \n",
    "    bone_mask_image_copy = np.expand_dims(bone_mask_image_copy, axis = -1)  \n",
    "    \n",
    "    # Predict \n",
    "    bone_mask_pred = model.predict(input_image_copy[np.newaxis,...]) \n",
    "    \n",
    "     # Squeeze\n",
    "    input_image_copy = np.squeeze(input_image_copy)\n",
    "    y_true = np.squeeze(bone_mask_image_copy)\n",
    "    y_pred = np.squeeze(bone_mask_pred)\n",
    "\n",
    "    y_pred[y_pred > 0.5] = 1\n",
    "    y_pred[y_pred <= 0.5] = 0\n",
    "        \n",
    "    # Calculate True Positive, True Negative, False Positive, False Negative\n",
    "    TP = np.sum(np.logical_and(y_pred == 1, y_true == 1))\n",
    "    TN = np.sum(np.logical_and(y_pred == 0, y_true == 0))\n",
    "    FP = np.sum(np.logical_and(y_pred == 1, y_true == 0))\n",
    "    FN = np.sum(np.logical_and(y_pred == 0, y_true == 1))\n",
    "\n",
    "    # Calculate Recall\n",
    "    recall = TP / (TP + FN)\n",
    "    \n",
    "    # Calculate Precision\n",
    "    precision =  TP / (TP + FP)\n",
    "    \n",
    "    # Calculate Recall\n",
    "    Dice = 2 * TP / (2 * TP + FP + FN)\n",
    "    \n",
    "    # Calculate Specificity\n",
    "    Jaccard = Dice / (2 - Dice)\n",
    "\n",
    "    # Calculate False Positive Rate\n",
    "    FPR =  FP / (FP + TN)\n",
    "    \n",
    "    # Calculate False Negative Rate\n",
    "    FNR = FN / (TP + FN)\n",
    "    \n",
    "    # Calculate Percentage of Wrong Classifications\n",
    "    PWC =  100 * (FN + FP) / (TP + FN + FP + TN)\n",
    "\n",
    "    stats = { 'input_image': input_image_path,\n",
    "              'bone_mask_image' : bone_mask_image,\n",
    "              'TP' : TP,\n",
    "              'TN' : TN,\n",
    "              'FP' : FP,\n",
    "              'FN' : FN,\n",
    "              'recall' : recall,\n",
    "              'precision' : precision,\n",
    "              'FPR' : FPR,\n",
    "              'FNR' : FNR,\n",
    "              'PWC' : PWC,\n",
    "              'Jaccard' : Jaccard,\n",
    "              'Dice' : Dice\n",
    "            }\n",
    "    \n",
    "    statistics.append(stats)\n",
    "    \n",
    "    measures[i][0] = TP\n",
    "    measures[i][1] = TN\n",
    "    measures[i][2] = FP\n",
    "    measures[i][3] = FN\n",
    "    measures[i][4] = recall\n",
    "    measures[i][5] = precision\n",
    "    measures[i][6] = FPR\n",
    "    measures[i][7] = FNR\n",
    "    measures[i][8] = PWC\n",
    "    measures[i][9] = Jaccard\n",
    "    measures[i][10] = Dice\n",
    "\n",
    "# Replace NaN by zeros\n",
    "measures[np.isnan(measures)] = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
